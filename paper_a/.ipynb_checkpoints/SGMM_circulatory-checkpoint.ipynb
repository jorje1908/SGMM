{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metricsFunctions import optimalTau, calc_metrics, sgmmResults, metrics_cluster\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervisedGmm import  SupervisedGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26296 221\n"
     ]
    }
   ],
   "source": [
    "sparcs = pd.read_csv(\"sparcs25%Circ_DeHos_Outflow_NYC_only.csv\") \n",
    "\n",
    "\n",
    "\n",
    "d_newborn_tr, d_newborn_te = train_test_split(sparcs, test_size=0.2, random_state = 1512)\n",
    "\n",
    "print(d_newborn_tr.shape[0], d_newborn_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21036, 221) (5260, 221)\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 2 CLUSTERS\n",
      "GMM iteration: 0, error: 7.70011661102281e-05\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 3 CLUSTERS\n",
      "GMM iteration: 0, error: 0.0012429832942493317\n",
      "GMM iteration: 1, error: 0.0003309961135612935\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 4 CLUSTERS\n",
      "GMM iteration: 0, error: 0.24837332798373615\n",
      "GMM iteration: 1, error: 0.17459578648182036\n",
      "GMM iteration: 2, error: 0.03998428013612885\n",
      "GMM iteration: 3, error: 0.011216619483228059\n",
      "GMM iteration: 4, error: 0.04367231661699573\n",
      "GMM iteration: 5, error: 0.009939592008472102\n",
      "GMM iteration: 6, error: 0.0030688328067457896\n",
      "GMM iteration: 7, error: 0.0009016459053194022\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 5 CLUSTERS\n",
      "GMM iteration: 0, error: 0.010003923313754368\n",
      "GMM iteration: 1, error: 0.008031172406400127\n",
      "GMM iteration: 2, error: 0.0029653479386467607\n",
      "GMM iteration: 3, error: 0.19330633379310955\n",
      "GMM iteration: 4, error: 0.14482378229766343\n",
      "GMM iteration: 5, error: 0.031632969561430885\n",
      "GMM iteration: 6, error: 0.015462795770145503\n",
      "GMM iteration: 7, error: 0.025486830524256772\n",
      "GMM iteration: 8, error: 0.007600774435764214\n",
      "GMM iteration: 9, error: 0.0023692257004338034\n",
      "GMM iteration: 10, error: 0.0011180199017014024\n",
      "GMM iteration: 11, error: 0.0007382040416142927\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 6 CLUSTERS\n",
      "GMM iteration: 0, error: 0.009402357707870637\n",
      "GMM iteration: 1, error: 0.11183912498201452\n",
      "GMM iteration: 2, error: 0.14306390226107707\n",
      "GMM iteration: 3, error: 0.041612417579441396\n",
      "GMM iteration: 4, error: 0.020942180212334054\n",
      "GMM iteration: 5, error: 0.023639717312552506\n",
      "GMM iteration: 6, error: 0.009273038326910055\n",
      "GMM iteration: 7, error: 0.0027704751434216857\n",
      "GMM iteration: 8, error: 0.0013243235972970387\n",
      "GMM iteration: 9, error: 0.0009491533881572523\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 7 CLUSTERS\n",
      "GMM iteration: 0, error: 0.018012627932290016\n",
      "GMM iteration: 1, error: 0.10781545587512777\n",
      "GMM iteration: 2, error: 0.11059429076415794\n",
      "GMM iteration: 3, error: 0.027582330221913042\n",
      "GMM iteration: 4, error: 0.007317475234366042\n",
      "GMM iteration: 5, error: 0.0028282311431399843\n",
      "GMM iteration: 6, error: 0.010091969825079584\n",
      "GMM iteration: 7, error: 0.02427249358977102\n",
      "GMM iteration: 8, error: 0.006296012673556834\n",
      "GMM iteration: 9, error: 0.004351577791808507\n",
      "GMM iteration: 10, error: 0.0015291551589419327\n",
      "GMM iteration: 11, error: 0.000508634687443732\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 8 CLUSTERS\n",
      "GMM iteration: 0, error: 0.008486020715547446\n",
      "GMM iteration: 1, error: 0.06501976026811475\n",
      "GMM iteration: 2, error: 0.11255398215315088\n",
      "GMM iteration: 3, error: 0.036560183714545155\n",
      "GMM iteration: 4, error: 0.009348592233788302\n",
      "GMM iteration: 5, error: 0.009297346171848108\n",
      "GMM iteration: 6, error: 0.007022089279399768\n",
      "GMM iteration: 7, error: 0.0027034905897161663\n",
      "GMM iteration: 8, error: 0.004573588099560785\n",
      "GMM iteration: 9, error: 0.004035764021486162\n",
      "GMM iteration: 10, error: 0.00473142561409801\n",
      "GMM iteration: 11, error: 0.001793406602484483\n",
      "GMM iteration: 12, error: 0.0004670012641295336\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 9 CLUSTERS\n",
      "GMM iteration: 0, error: 0.023126094888515848\n",
      "GMM iteration: 1, error: 0.09390130878103292\n",
      "GMM iteration: 2, error: 0.05244856504110549\n",
      "GMM iteration: 3, error: 0.024441675793088695\n",
      "GMM iteration: 4, error: 0.019211804902445163\n",
      "GMM iteration: 5, error: 0.017068271924425414\n",
      "GMM iteration: 6, error: 0.008969121436073146\n",
      "GMM iteration: 7, error: 0.00313713383878539\n",
      "GMM iteration: 8, error: 0.0014879743541451919\n",
      "GMM iteration: 9, error: 0.000678138701762537\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 10 CLUSTERS\n",
      "GMM iteration: 0, error: 0.02805421940013537\n",
      "GMM iteration: 1, error: 0.08021540944961354\n",
      "GMM iteration: 2, error: 0.045492381311856435\n",
      "GMM iteration: 3, error: 0.026789788330622823\n",
      "GMM iteration: 4, error: 0.008667040071288585\n",
      "GMM iteration: 5, error: 0.0042204707023149315\n",
      "GMM iteration: 6, error: 0.0032275048724445957\n",
      "GMM iteration: 7, error: 0.0018341049024661825\n",
      "GMM iteration: 8, error: 0.002798511791137439\n",
      "GMM iteration: 9, error: 0.003281047432056596\n",
      "GMM iteration: 10, error: 0.0036225788002734838\n",
      "GMM iteration: 11, error: 0.003984575267928253\n",
      "GMM iteration: 12, error: 0.0012415014486972303\n",
      "GMM iteration: 13, error: 0.0008242234462925949\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 11 CLUSTERS\n",
      "GMM iteration: 0, error: 0.048867681994781934\n",
      "GMM iteration: 1, error: 0.05919062746879057\n",
      "GMM iteration: 2, error: 0.04724138788570876\n",
      "GMM iteration: 3, error: 0.014318227263186939\n",
      "GMM iteration: 4, error: 0.0038471499645898748\n",
      "GMM iteration: 5, error: 0.0014190474207560549\n",
      "GMM iteration: 6, error: 0.0008077496930449517\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 12 CLUSTERS\n",
      "GMM iteration: 0, error: 0.02736362899903903\n",
      "GMM iteration: 1, error: 0.029345361899081525\n",
      "GMM iteration: 2, error: 0.054111925561897346\n",
      "GMM iteration: 3, error: 0.02482749329081915\n",
      "GMM iteration: 4, error: 0.006600005074644963\n",
      "GMM iteration: 5, error: 0.0023096251119324616\n",
      "GMM iteration: 6, error: 0.0028547223604695584\n",
      "GMM iteration: 7, error: 0.007501835301126259\n",
      "GMM iteration: 8, error: 0.00559687918181184\n",
      "GMM iteration: 9, error: 0.0032168502333310696\n",
      "GMM iteration: 10, error: 0.0026659892639903583\n",
      "GMM iteration: 11, error: 0.0011583704469985167\n",
      "GMM iteration: 12, error: 0.0003961939802501375\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 13 CLUSTERS\n",
      "GMM iteration: 0, error: 0.008396257407378966\n",
      "GMM iteration: 1, error: 0.01871654107960744\n",
      "GMM iteration: 2, error: 0.05556941810251903\n",
      "GMM iteration: 3, error: 0.05257049443685396\n",
      "GMM iteration: 4, error: 0.012907824945247068\n",
      "GMM iteration: 5, error: 0.004595835239555499\n",
      "GMM iteration: 6, error: 0.004873956743913869\n",
      "GMM iteration: 7, error: 0.004846863446385406\n",
      "GMM iteration: 8, error: 0.005655059087025678\n",
      "GMM iteration: 9, error: 0.0017453283391651946\n",
      "GMM iteration: 10, error: 0.0011172619706343594\n",
      "GMM iteration: 11, error: 0.000611442941557866\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 14 CLUSTERS\n",
      "GMM iteration: 0, error: 0.01761532557759228\n",
      "GMM iteration: 1, error: 0.01179198788144592\n",
      "GMM iteration: 2, error: 0.01593016683936697\n",
      "GMM iteration: 3, error: 0.016450086490398648\n",
      "GMM iteration: 4, error: 0.010569224443478853\n",
      "GMM iteration: 5, error: 0.004133333781580725\n",
      "GMM iteration: 6, error: 0.003463978894266203\n",
      "GMM iteration: 7, error: 0.007982029047273098\n",
      "GMM iteration: 8, error: 0.011732690637846809\n",
      "GMM iteration: 9, error: 0.011604350827583354\n",
      "GMM iteration: 10, error: 0.008419135819741937\n",
      "GMM iteration: 11, error: 0.005400830354734201\n",
      "GMM iteration: 12, error: 0.0034976847564253473\n",
      "GMM iteration: 13, error: 0.004469996340264292\n",
      "GMM iteration: 14, error: 0.002612769889089925\n",
      "GMM iteration: 15, error: 0.0025895756311663737\n",
      "GMM iteration: 16, error: 0.0014976093146122187\n",
      "GMM iteration: 17, error: 0.0010312601566582456\n",
      "GMM iteration: 18, error: 0.004535444558688438\n",
      "GMM iteration: 19, error: 0.002805169139333882\n",
      "GMM iteration: 20, error: 0.0011963806588682064\n",
      "GMM iteration: 21, error: 0.0008147439579738135\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 15 CLUSTERS\n",
      "GMM iteration: 0, error: 0.015356944473299466\n",
      "GMM iteration: 1, error: 0.011676248962435791\n",
      "GMM iteration: 2, error: 0.01473092017459926\n",
      "GMM iteration: 3, error: 0.010647562649643519\n",
      "GMM iteration: 4, error: 0.006604194976433208\n",
      "GMM iteration: 5, error: 0.009481824728600177\n",
      "GMM iteration: 6, error: 0.011223763244317148\n",
      "GMM iteration: 7, error: 0.00778422365352553\n",
      "GMM iteration: 8, error: 0.005476429940350197\n",
      "GMM iteration: 9, error: 0.0042867252815707736\n",
      "GMM iteration: 10, error: 0.0019500690093834105\n",
      "GMM iteration: 11, error: 0.0009581212915293449\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 16 CLUSTERS\n",
      "GMM iteration: 0, error: 0.008313510162498436\n",
      "GMM iteration: 1, error: 0.019901407742759513\n",
      "GMM iteration: 2, error: 0.019864321665061316\n",
      "GMM iteration: 3, error: 0.005187429436824339\n",
      "GMM iteration: 4, error: 0.004660074825924235\n",
      "GMM iteration: 5, error: 0.004047760322503349\n",
      "GMM iteration: 6, error: 0.003918466595674865\n",
      "GMM iteration: 7, error: 0.009046449475890735\n",
      "GMM iteration: 8, error: 0.01992497790527085\n",
      "GMM iteration: 9, error: 0.009598529118440639\n",
      "GMM iteration: 10, error: 0.009018376289532344\n",
      "GMM iteration: 11, error: 0.013519642334736407\n",
      "GMM iteration: 12, error: 0.007854738883740326\n",
      "GMM iteration: 13, error: 0.0024450015129447037\n",
      "GMM iteration: 14, error: 0.001383374546555089\n",
      "GMM iteration: 15, error: 0.0033196349470120197\n",
      "GMM iteration: 16, error: 0.008626896786298207\n",
      "GMM iteration: 17, error: 0.01108920431430026\n",
      "GMM iteration: 18, error: 0.009705754494105519\n",
      "GMM iteration: 19, error: 0.003075500861476754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM iteration: 20, error: 0.0021507849743471518\n",
      "GMM iteration: 21, error: 0.0013336154394183327\n",
      "GMM iteration: 22, error: 0.0009199754856538472\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 17 CLUSTERS\n",
      "GMM iteration: 0, error: 0.04951969493177771\n",
      "GMM iteration: 1, error: 0.01975536745957423\n",
      "GMM iteration: 2, error: 0.02129515418826615\n",
      "GMM iteration: 3, error: 0.015326864568939644\n",
      "GMM iteration: 4, error: 0.0048425128693485985\n",
      "GMM iteration: 5, error: 0.0019575946709391823\n",
      "GMM iteration: 6, error: 0.00593252423971614\n",
      "GMM iteration: 7, error: 0.004580184312478803\n",
      "GMM iteration: 8, error: 0.002117505293244431\n",
      "GMM iteration: 9, error: 0.0022021833991071266\n",
      "GMM iteration: 10, error: 0.0015242682732439406\n",
      "GMM iteration: 11, error: 0.0007854574031789818\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 18 CLUSTERS\n",
      "GMM iteration: 0, error: 0.006200067686308366\n",
      "GMM iteration: 1, error: 0.002654662461701774\n",
      "GMM iteration: 2, error: 0.0010624876146425836\n",
      "GMM iteration: 3, error: 0.003976535965916614\n",
      "GMM iteration: 4, error: 0.008073668826979496\n",
      "GMM iteration: 5, error: 0.007700763320656669\n",
      "GMM iteration: 6, error: 0.004939067716631701\n",
      "GMM iteration: 7, error: 0.005758665704548275\n",
      "GMM iteration: 8, error: 0.00683137605272858\n",
      "GMM iteration: 9, error: 0.006543133717158203\n",
      "GMM iteration: 10, error: 0.010074730264484473\n",
      "GMM iteration: 11, error: 0.011043911180861033\n",
      "GMM iteration: 12, error: 0.01654495248204475\n",
      "GMM iteration: 13, error: 0.01042957508453802\n",
      "GMM iteration: 14, error: 0.005439912610964173\n",
      "GMM iteration: 15, error: 0.003994829347082526\n",
      "GMM iteration: 16, error: 0.008535124398153902\n",
      "GMM iteration: 17, error: 0.003262892225694175\n",
      "GMM iteration: 18, error: 0.0013069469556843047\n",
      "GMM iteration: 19, error: 0.0006237770973372804\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 19 CLUSTERS\n",
      "GMM iteration: 0, error: 0.018459886153727435\n",
      "GMM iteration: 1, error: 0.004446277469724524\n",
      "GMM iteration: 2, error: 0.002175355664326153\n",
      "GMM iteration: 3, error: 0.015595428217667035\n",
      "GMM iteration: 4, error: 0.018633295961642826\n",
      "GMM iteration: 5, error: 0.015386572201160105\n",
      "GMM iteration: 6, error: 0.008130723609460572\n",
      "GMM iteration: 7, error: 0.006424686672985516\n",
      "GMM iteration: 8, error: 0.0049979892556650226\n",
      "GMM iteration: 9, error: 0.0026035835410721064\n",
      "GMM iteration: 10, error: 0.0012698871824610497\n",
      "GMM iteration: 11, error: 0.0009584813216368872\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 20 CLUSTERS\n",
      "GMM iteration: 0, error: 0.005516438096478578\n",
      "GMM iteration: 1, error: 0.0017101685214270925\n",
      "GMM iteration: 2, error: 0.0006677297873911701\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 21 CLUSTERS\n",
      "GMM iteration: 0, error: 0.0049366214061212655\n",
      "GMM iteration: 1, error: 0.002034282335431358\n",
      "GMM iteration: 2, error: 0.0006428634478549745\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 22 CLUSTERS\n",
      "GMM iteration: 0, error: 0.0021615370966823555\n",
      "GMM iteration: 1, error: 0.000925036217021361\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 23 CLUSTERS\n",
      "GMM iteration: 0, error: 0.0018320386635079383\n",
      "GMM iteration: 1, error: 0.0006830408822601812\n",
      "\n",
      "\n",
      "\n",
      "TRAINING WITH 24 CLUSTERS\n",
      "GMM iteration: 0, error: 0.006070573352124068\n",
      "GMM iteration: 1, error: 0.0031982130175900606\n",
      "GMM iteration: 2, error: 0.004186606551424255\n",
      "GMM iteration: 3, error: 0.007702817696334559\n",
      "GMM iteration: 4, error: 0.007317726374295319\n",
      "GMM iteration: 5, error: 0.004770187498916401\n",
      "GMM iteration: 6, error: 0.006418349595749132\n",
      "GMM iteration: 7, error: 0.01535240900966416\n",
      "GMM iteration: 8, error: 0.011378998265471762\n",
      "GMM iteration: 9, error: 0.01266952078880581\n",
      "GMM iteration: 10, error: 0.004194410323143321\n",
      "GMM iteration: 11, error: 0.0043038304802362\n",
      "GMM iteration: 12, error: 0.00932710152465432\n",
      "GMM iteration: 13, error: 0.005459985662898719\n",
      "GMM iteration: 14, error: 0.0019174337244420572\n",
      "GMM iteration: 15, error: 0.0008865417722562085\n",
      "time elapsed: 41962.696622133255\n"
     ]
    }
   ],
   "source": [
    "#VALIDATION ON CLUSTERS\n",
    "#RUN VALIDATION ON NUMBER OF CLUSTERS BASED ON AUC\n",
    "import time\n",
    "\n",
    "train, val = train_test_split(d_newborn_tr, test_size = 0.2, random_state = 1512)\n",
    "y_train, y_val = train.iloc[:,-1], val.iloc[:,-1]\n",
    "\n",
    "print( train.shape, val.shape )\n",
    "\n",
    "#SET SGMM PARAMETERS\n",
    "#regularization parameters\n",
    "C = [0.01, 0.1, 1, 5, 10, 15, 20, 50]\n",
    "max_iter2 = 30\n",
    "\n",
    "train_np = train.iloc[:,0:-1].values\n",
    "val_np = val.iloc[:,0:-1].values\n",
    "\n",
    "y_train_np = y_train.values\n",
    "y_val_np = y_val.values\n",
    "\n",
    "test_re = []\n",
    "train_re = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#test clusters 0-12\n",
    "for i in range(2,25):\n",
    "    print(\"\\n\\n\\nTRAINING WITH {} CLUSTERS\".format(i))\n",
    "    model = SupervisedGMM(C = C, max_iter2 = max_iter2, n_clusters = i, verbose = 0)\n",
    "    model = model.fit(Xtrain = train_np, ytrain = y_train_np)\n",
    "    probTrain = model.predict_proba( train_np )\n",
    "    probTest = model.predict_proba( val_np )\n",
    "    results = sgmmResults( model, probTest.copy(), probTrain.copy(), y_val_np.copy(), y_train_np.copy(), tau = None,\n",
    "                mode = 0)\n",
    "    testmetrics = results['testMet']\n",
    "    trainMetrics = results[ 'trainMet']\n",
    "    test_re.append( testmetrics )\n",
    "    train_re.append( trainMetrics )\n",
    "    \n",
    "end = time.time() - start\n",
    "print(\"time elapsed: {}\".format( end ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>size</th>\n",
       "      <th>high_cost%</th>\n",
       "      <th>low_cost%</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>816.0</td>\n",
       "      <td>3484.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.880910</td>\n",
       "      <td>0.625287</td>\n",
       "      <td>0.634033</td>\n",
       "      <td>0.817490</td>\n",
       "      <td>0.753099</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.854219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>888.0</td>\n",
       "      <td>3339.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.155752</td>\n",
       "      <td>0.844248</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.803612</td>\n",
       "      <td>0.762354</td>\n",
       "      <td>0.632253</td>\n",
       "      <td>0.853148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>856.0</td>\n",
       "      <td>3399.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.140582</td>\n",
       "      <td>0.859418</td>\n",
       "      <td>0.655939</td>\n",
       "      <td>0.606232</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.757679</td>\n",
       "      <td>0.630107</td>\n",
       "      <td>0.853188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3518.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.110493</td>\n",
       "      <td>0.889507</td>\n",
       "      <td>0.613027</td>\n",
       "      <td>0.646726</td>\n",
       "      <td>0.820913</td>\n",
       "      <td>0.751267</td>\n",
       "      <td>0.629426</td>\n",
       "      <td>0.853688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>919.0</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>0.174968</td>\n",
       "      <td>0.825032</td>\n",
       "      <td>0.704215</td>\n",
       "      <td>0.570453</td>\n",
       "      <td>0.795057</td>\n",
       "      <td>0.764623</td>\n",
       "      <td>0.630316</td>\n",
       "      <td>0.853420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>868.0</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>0.142351</td>\n",
       "      <td>0.857649</td>\n",
       "      <td>0.665134</td>\n",
       "      <td>0.606569</td>\n",
       "      <td>0.809886</td>\n",
       "      <td>0.761391</td>\n",
       "      <td>0.634503</td>\n",
       "      <td>0.853542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>868.0</td>\n",
       "      <td>3399.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>0.140582</td>\n",
       "      <td>0.859418</td>\n",
       "      <td>0.665134</td>\n",
       "      <td>0.609551</td>\n",
       "      <td>0.811217</td>\n",
       "      <td>0.762276</td>\n",
       "      <td>0.636130</td>\n",
       "      <td>0.854232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>825.0</td>\n",
       "      <td>3469.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.122882</td>\n",
       "      <td>0.877118</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.816350</td>\n",
       "      <td>0.754651</td>\n",
       "      <td>0.630734</td>\n",
       "      <td>0.852118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>822.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>0.127686</td>\n",
       "      <td>0.872314</td>\n",
       "      <td>0.629885</td>\n",
       "      <td>0.619442</td>\n",
       "      <td>0.812167</td>\n",
       "      <td>0.751099</td>\n",
       "      <td>0.624620</td>\n",
       "      <td>0.851619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>810.0</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.126675</td>\n",
       "      <td>0.873325</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.810646</td>\n",
       "      <td>0.747007</td>\n",
       "      <td>0.619266</td>\n",
       "      <td>0.847010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>858.0</td>\n",
       "      <td>3386.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>0.143869</td>\n",
       "      <td>0.856131</td>\n",
       "      <td>0.657471</td>\n",
       "      <td>0.601261</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.628111</td>\n",
       "      <td>0.851061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>843.0</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.140076</td>\n",
       "      <td>0.859924</td>\n",
       "      <td>0.645977</td>\n",
       "      <td>0.603436</td>\n",
       "      <td>0.806844</td>\n",
       "      <td>0.752951</td>\n",
       "      <td>0.623982</td>\n",
       "      <td>0.848205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>828.0</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.124147</td>\n",
       "      <td>0.875853</td>\n",
       "      <td>0.634483</td>\n",
       "      <td>0.627748</td>\n",
       "      <td>0.815970</td>\n",
       "      <td>0.755168</td>\n",
       "      <td>0.631098</td>\n",
       "      <td>0.849508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>859.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>0.146650</td>\n",
       "      <td>0.853350</td>\n",
       "      <td>0.658238</td>\n",
       "      <td>0.596942</td>\n",
       "      <td>0.804943</td>\n",
       "      <td>0.755794</td>\n",
       "      <td>0.626093</td>\n",
       "      <td>0.851311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>854.0</td>\n",
       "      <td>3397.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.141087</td>\n",
       "      <td>0.858913</td>\n",
       "      <td>0.654406</td>\n",
       "      <td>0.604816</td>\n",
       "      <td>0.808175</td>\n",
       "      <td>0.756659</td>\n",
       "      <td>0.628635</td>\n",
       "      <td>0.847634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>869.0</td>\n",
       "      <td>3369.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.148167</td>\n",
       "      <td>0.851833</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.597251</td>\n",
       "      <td>0.805703</td>\n",
       "      <td>0.758867</td>\n",
       "      <td>0.629710</td>\n",
       "      <td>0.851886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>787.0</td>\n",
       "      <td>3438.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.869279</td>\n",
       "      <td>0.603065</td>\n",
       "      <td>0.603528</td>\n",
       "      <td>0.803232</td>\n",
       "      <td>0.736172</td>\n",
       "      <td>0.603296</td>\n",
       "      <td>0.843679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>888.0</td>\n",
       "      <td>3374.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>0.146903</td>\n",
       "      <td>0.853097</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>0.604493</td>\n",
       "      <td>0.810266</td>\n",
       "      <td>0.766779</td>\n",
       "      <td>0.640231</td>\n",
       "      <td>0.854731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>786.0</td>\n",
       "      <td>3439.0</td>\n",
       "      <td>516.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.130468</td>\n",
       "      <td>0.869532</td>\n",
       "      <td>0.602299</td>\n",
       "      <td>0.603687</td>\n",
       "      <td>0.803232</td>\n",
       "      <td>0.735916</td>\n",
       "      <td>0.602992</td>\n",
       "      <td>0.841559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>877.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.178255</td>\n",
       "      <td>0.821745</td>\n",
       "      <td>0.672031</td>\n",
       "      <td>0.554362</td>\n",
       "      <td>0.784601</td>\n",
       "      <td>0.746888</td>\n",
       "      <td>0.607551</td>\n",
       "      <td>0.836579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>786.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>0.131985</td>\n",
       "      <td>0.868015</td>\n",
       "      <td>0.602299</td>\n",
       "      <td>0.600917</td>\n",
       "      <td>0.802091</td>\n",
       "      <td>0.735157</td>\n",
       "      <td>0.601607</td>\n",
       "      <td>0.838366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>753.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.116814</td>\n",
       "      <td>0.883186</td>\n",
       "      <td>0.577011</td>\n",
       "      <td>0.619753</td>\n",
       "      <td>0.807224</td>\n",
       "      <td>0.730099</td>\n",
       "      <td>0.597619</td>\n",
       "      <td>0.836813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>5260.0</td>\n",
       "      <td>0.248099</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>883.0</td>\n",
       "      <td>3296.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>0.166625</td>\n",
       "      <td>0.833375</td>\n",
       "      <td>0.676628</td>\n",
       "      <td>0.572633</td>\n",
       "      <td>0.794487</td>\n",
       "      <td>0.755002</td>\n",
       "      <td>0.620302</td>\n",
       "      <td>0.843693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster    size  high_cost%  low_cost%     TP      TN     FP     FN  \\\n",
       "0      -1.0  5260.0    0.248099   0.751901  816.0  3484.0  471.0  489.0   \n",
       "1      -1.0  5260.0    0.248099   0.751901  888.0  3339.0  616.0  417.0   \n",
       "2      -1.0  5260.0    0.248099   0.751901  856.0  3399.0  556.0  449.0   \n",
       "3      -1.0  5260.0    0.248099   0.751901  800.0  3518.0  437.0  505.0   \n",
       "4      -1.0  5260.0    0.248099   0.751901  919.0  3263.0  692.0  386.0   \n",
       "5      -1.0  5260.0    0.248099   0.751901  868.0  3392.0  563.0  437.0   \n",
       "6      -1.0  5260.0    0.248099   0.751901  868.0  3399.0  556.0  437.0   \n",
       "7      -1.0  5260.0    0.248099   0.751901  825.0  3469.0  486.0  480.0   \n",
       "8      -1.0  5260.0    0.248099   0.751901  822.0  3450.0  505.0  483.0   \n",
       "9      -1.0  5260.0    0.248099   0.751901  810.0  3454.0  501.0  495.0   \n",
       "10     -1.0  5260.0    0.248099   0.751901  858.0  3386.0  569.0  447.0   \n",
       "11     -1.0  5260.0    0.248099   0.751901  843.0  3401.0  554.0  462.0   \n",
       "12     -1.0  5260.0    0.248099   0.751901  828.0  3464.0  491.0  477.0   \n",
       "13     -1.0  5260.0    0.248099   0.751901  859.0  3375.0  580.0  446.0   \n",
       "14     -1.0  5260.0    0.248099   0.751901  854.0  3397.0  558.0  451.0   \n",
       "15     -1.0  5260.0    0.248099   0.751901  869.0  3369.0  586.0  436.0   \n",
       "16     -1.0  5260.0    0.248099   0.751901  787.0  3438.0  517.0  518.0   \n",
       "17     -1.0  5260.0    0.248099   0.751901  888.0  3374.0  581.0  417.0   \n",
       "18     -1.0  5260.0    0.248099   0.751901  786.0  3439.0  516.0  519.0   \n",
       "19     -1.0  5260.0    0.248099   0.751901  877.0  3250.0  705.0  428.0   \n",
       "20     -1.0  5260.0    0.248099   0.751901  786.0  3433.0  522.0  519.0   \n",
       "21     -1.0  5260.0    0.248099   0.751901  753.0  3493.0  462.0  552.0   \n",
       "22     -1.0  5260.0    0.248099   0.751901  883.0  3296.0  659.0  422.0   \n",
       "\n",
       "         FPR  specificity  sensitivity  precision  accuracy  \\\n",
       "0   0.119090     0.880910     0.625287   0.634033  0.817490   \n",
       "1   0.155752     0.844248     0.680460   0.590426  0.803612   \n",
       "2   0.140582     0.859418     0.655939   0.606232  0.808935   \n",
       "3   0.110493     0.889507     0.613027   0.646726  0.820913   \n",
       "4   0.174968     0.825032     0.704215   0.570453  0.795057   \n",
       "5   0.142351     0.857649     0.665134   0.606569  0.809886   \n",
       "6   0.140582     0.859418     0.665134   0.609551  0.811217   \n",
       "7   0.122882     0.877118     0.632184   0.629291  0.816350   \n",
       "8   0.127686     0.872314     0.629885   0.619442  0.812167   \n",
       "9   0.126675     0.873325     0.620690   0.617849  0.810646   \n",
       "10  0.143869     0.856131     0.657471   0.601261  0.806844   \n",
       "11  0.140076     0.859924     0.645977   0.603436  0.806844   \n",
       "12  0.124147     0.875853     0.634483   0.627748  0.815970   \n",
       "13  0.146650     0.853350     0.658238   0.596942  0.804943   \n",
       "14  0.141087     0.858913     0.654406   0.604816  0.808175   \n",
       "15  0.148167     0.851833     0.665900   0.597251  0.805703   \n",
       "16  0.130721     0.869279     0.603065   0.603528  0.803232   \n",
       "17  0.146903     0.853097     0.680460   0.604493  0.810266   \n",
       "18  0.130468     0.869532     0.602299   0.603687  0.803232   \n",
       "19  0.178255     0.821745     0.672031   0.554362  0.784601   \n",
       "20  0.131985     0.868015     0.602299   0.600917  0.802091   \n",
       "21  0.116814     0.883186     0.577011   0.619753  0.807224   \n",
       "22  0.166625     0.833375     0.676628   0.572633  0.794487   \n",
       "\n",
       "    balanced accuracy        f1       auc  \n",
       "0            0.753099  0.629630  0.854219  \n",
       "1            0.762354  0.632253  0.853148  \n",
       "2            0.757679  0.630107  0.853188  \n",
       "3            0.751267  0.629426  0.853688  \n",
       "4            0.764623  0.630316  0.853420  \n",
       "5            0.761391  0.634503  0.853542  \n",
       "6            0.762276  0.636130  0.854232  \n",
       "7            0.754651  0.630734  0.852118  \n",
       "8            0.751099  0.624620  0.851619  \n",
       "9            0.747007  0.619266  0.847010  \n",
       "10           0.756801  0.628111  0.851061  \n",
       "11           0.752951  0.623982  0.848205  \n",
       "12           0.755168  0.631098  0.849508  \n",
       "13           0.755794  0.626093  0.851311  \n",
       "14           0.756659  0.628635  0.847634  \n",
       "15           0.758867  0.629710  0.851886  \n",
       "16           0.736172  0.603296  0.843679  \n",
       "17           0.766779  0.640231  0.854731  \n",
       "18           0.735916  0.602992  0.841559  \n",
       "19           0.746888  0.607551  0.836579  \n",
       "20           0.735157  0.601607  0.838366  \n",
       "21           0.730099  0.597619  0.836813  \n",
       "22           0.755002  0.620302  0.843693  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PICK THE CLUSTERS\n",
    "columns = test_re[0].columns\n",
    "pdi = pd.DataFrame(np.zeros(shape = [len(test_re), test_re[0].shape[1]]), columns = columns)\n",
    "pdi_tr = pd.DataFrame(np.zeros(shape = [len(train_re), train_re[0].shape[1]]), columns = columns)\n",
    "\n",
    "for i, panda in enumerate(test_re):\n",
    "     pdi.iloc[i,:] = panda.iloc[0,:]\n",
    "        \n",
    "for i, panda in enumerate(train_re):\n",
    "     pdi_tr.iloc[i,:] = panda.iloc[0,:]\n",
    "\n",
    "pdi.round(6)\n",
    "#BASED ON THAT WE PICK 9 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>size</th>\n",
       "      <th>high_cost%</th>\n",
       "      <th>low_cost%</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>13881.0</td>\n",
       "      <td>1856.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>0.117939</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>0.652010</td>\n",
       "      <td>0.650537</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.651272</td>\n",
       "      <td>0.865983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3745.0</td>\n",
       "      <td>13325.0</td>\n",
       "      <td>2412.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>0.153269</td>\n",
       "      <td>0.846731</td>\n",
       "      <td>0.706737</td>\n",
       "      <td>0.608251</td>\n",
       "      <td>0.811466</td>\n",
       "      <td>0.776734</td>\n",
       "      <td>0.653806</td>\n",
       "      <td>0.868766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3634.0</td>\n",
       "      <td>13534.0</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>0.139989</td>\n",
       "      <td>0.860011</td>\n",
       "      <td>0.685790</td>\n",
       "      <td>0.622580</td>\n",
       "      <td>0.816125</td>\n",
       "      <td>0.772901</td>\n",
       "      <td>0.652658</td>\n",
       "      <td>0.866253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3383.0</td>\n",
       "      <td>14038.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>0.107962</td>\n",
       "      <td>0.892038</td>\n",
       "      <td>0.638422</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.765230</td>\n",
       "      <td>0.651768</td>\n",
       "      <td>0.865983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3858.0</td>\n",
       "      <td>13048.0</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>0.170871</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.728062</td>\n",
       "      <td>0.589278</td>\n",
       "      <td>0.803670</td>\n",
       "      <td>0.778595</td>\n",
       "      <td>0.651359</td>\n",
       "      <td>0.866293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3648.0</td>\n",
       "      <td>13522.0</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>0.140751</td>\n",
       "      <td>0.859249</td>\n",
       "      <td>0.688432</td>\n",
       "      <td>0.622207</td>\n",
       "      <td>0.816220</td>\n",
       "      <td>0.773840</td>\n",
       "      <td>0.653646</td>\n",
       "      <td>0.867091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3664.0</td>\n",
       "      <td>13532.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>1635.0</td>\n",
       "      <td>0.140116</td>\n",
       "      <td>0.859884</td>\n",
       "      <td>0.691451</td>\n",
       "      <td>0.624297</td>\n",
       "      <td>0.817456</td>\n",
       "      <td>0.775668</td>\n",
       "      <td>0.656160</td>\n",
       "      <td>0.868717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>13805.0</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>1773.0</td>\n",
       "      <td>0.122768</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.665409</td>\n",
       "      <td>0.646024</td>\n",
       "      <td>0.823873</td>\n",
       "      <td>0.771320</td>\n",
       "      <td>0.655573</td>\n",
       "      <td>0.867634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3544.0</td>\n",
       "      <td>13847.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>0.120099</td>\n",
       "      <td>0.879901</td>\n",
       "      <td>0.668805</td>\n",
       "      <td>0.652190</td>\n",
       "      <td>0.826726</td>\n",
       "      <td>0.774353</td>\n",
       "      <td>0.660393</td>\n",
       "      <td>0.870440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>13943.0</td>\n",
       "      <td>1794.0</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>0.113999</td>\n",
       "      <td>0.886001</td>\n",
       "      <td>0.655784</td>\n",
       "      <td>0.659518</td>\n",
       "      <td>0.828009</td>\n",
       "      <td>0.770893</td>\n",
       "      <td>0.657646</td>\n",
       "      <td>0.869842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>13617.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>0.134714</td>\n",
       "      <td>0.865286</td>\n",
       "      <td>0.683903</td>\n",
       "      <td>0.630919</td>\n",
       "      <td>0.819595</td>\n",
       "      <td>0.774594</td>\n",
       "      <td>0.656343</td>\n",
       "      <td>0.867364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>13577.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>0.137256</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.681449</td>\n",
       "      <td>0.625715</td>\n",
       "      <td>0.817075</td>\n",
       "      <td>0.772097</td>\n",
       "      <td>0.652394</td>\n",
       "      <td>0.864976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3555.0</td>\n",
       "      <td>13866.0</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>0.118892</td>\n",
       "      <td>0.881108</td>\n",
       "      <td>0.670881</td>\n",
       "      <td>0.655179</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.775995</td>\n",
       "      <td>0.662937</td>\n",
       "      <td>0.873003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3680.0</td>\n",
       "      <td>13577.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>0.137256</td>\n",
       "      <td>0.862744</td>\n",
       "      <td>0.694471</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.820356</td>\n",
       "      <td>0.778607</td>\n",
       "      <td>0.660742</td>\n",
       "      <td>0.872713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3637.0</td>\n",
       "      <td>13680.0</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>1662.0</td>\n",
       "      <td>0.130711</td>\n",
       "      <td>0.869289</td>\n",
       "      <td>0.686356</td>\n",
       "      <td>0.638743</td>\n",
       "      <td>0.823208</td>\n",
       "      <td>0.777822</td>\n",
       "      <td>0.661694</td>\n",
       "      <td>0.870665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3661.0</td>\n",
       "      <td>13520.0</td>\n",
       "      <td>2217.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>0.140878</td>\n",
       "      <td>0.859122</td>\n",
       "      <td>0.690885</td>\n",
       "      <td>0.622831</td>\n",
       "      <td>0.816743</td>\n",
       "      <td>0.775003</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>0.864621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3467.0</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>0.123086</td>\n",
       "      <td>0.876914</td>\n",
       "      <td>0.654274</td>\n",
       "      <td>0.641562</td>\n",
       "      <td>0.820831</td>\n",
       "      <td>0.765594</td>\n",
       "      <td>0.647856</td>\n",
       "      <td>0.861911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>13590.0</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.136430</td>\n",
       "      <td>0.863570</td>\n",
       "      <td>0.704284</td>\n",
       "      <td>0.634802</td>\n",
       "      <td>0.823446</td>\n",
       "      <td>0.783927</td>\n",
       "      <td>0.667740</td>\n",
       "      <td>0.876492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3573.0</td>\n",
       "      <td>14002.0</td>\n",
       "      <td>1735.0</td>\n",
       "      <td>1726.0</td>\n",
       "      <td>0.110250</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.674278</td>\n",
       "      <td>0.673135</td>\n",
       "      <td>0.835473</td>\n",
       "      <td>0.782014</td>\n",
       "      <td>0.673706</td>\n",
       "      <td>0.883135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3887.0</td>\n",
       "      <td>13271.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>0.156701</td>\n",
       "      <td>0.843299</td>\n",
       "      <td>0.733535</td>\n",
       "      <td>0.611837</td>\n",
       "      <td>0.815649</td>\n",
       "      <td>0.788417</td>\n",
       "      <td>0.667182</td>\n",
       "      <td>0.879088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3591.0</td>\n",
       "      <td>13932.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>0.114698</td>\n",
       "      <td>0.885302</td>\n",
       "      <td>0.677675</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.781489</td>\n",
       "      <td>0.671529</td>\n",
       "      <td>0.879739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3451.0</td>\n",
       "      <td>14178.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>1848.0</td>\n",
       "      <td>0.099066</td>\n",
       "      <td>0.900934</td>\n",
       "      <td>0.651255</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.838040</td>\n",
       "      <td>0.776095</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.879535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>21036.0</td>\n",
       "      <td>0.251902</td>\n",
       "      <td>0.748098</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>13271.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>1519.0</td>\n",
       "      <td>0.156701</td>\n",
       "      <td>0.843299</td>\n",
       "      <td>0.713342</td>\n",
       "      <td>0.605187</td>\n",
       "      <td>0.810563</td>\n",
       "      <td>0.778321</td>\n",
       "      <td>0.654829</td>\n",
       "      <td>0.864204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster     size  high_cost%  low_cost%      TP       TN      FP      FN  \\\n",
       "0      -1.0  21036.0    0.251902   0.748098  3455.0  13881.0  1856.0  1844.0   \n",
       "1      -1.0  21036.0    0.251902   0.748098  3745.0  13325.0  2412.0  1554.0   \n",
       "2      -1.0  21036.0    0.251902   0.748098  3634.0  13534.0  2203.0  1665.0   \n",
       "3      -1.0  21036.0    0.251902   0.748098  3383.0  14038.0  1699.0  1916.0   \n",
       "4      -1.0  21036.0    0.251902   0.748098  3858.0  13048.0  2689.0  1441.0   \n",
       "5      -1.0  21036.0    0.251902   0.748098  3648.0  13522.0  2215.0  1651.0   \n",
       "6      -1.0  21036.0    0.251902   0.748098  3664.0  13532.0  2205.0  1635.0   \n",
       "7      -1.0  21036.0    0.251902   0.748098  3526.0  13805.0  1932.0  1773.0   \n",
       "8      -1.0  21036.0    0.251902   0.748098  3544.0  13847.0  1890.0  1755.0   \n",
       "9      -1.0  21036.0    0.251902   0.748098  3475.0  13943.0  1794.0  1824.0   \n",
       "10     -1.0  21036.0    0.251902   0.748098  3624.0  13617.0  2120.0  1675.0   \n",
       "11     -1.0  21036.0    0.251902   0.748098  3611.0  13577.0  2160.0  1688.0   \n",
       "12     -1.0  21036.0    0.251902   0.748098  3555.0  13866.0  1871.0  1744.0   \n",
       "13     -1.0  21036.0    0.251902   0.748098  3680.0  13577.0  2160.0  1619.0   \n",
       "14     -1.0  21036.0    0.251902   0.748098  3637.0  13680.0  2057.0  1662.0   \n",
       "15     -1.0  21036.0    0.251902   0.748098  3661.0  13520.0  2217.0  1638.0   \n",
       "16     -1.0  21036.0    0.251902   0.748098  3467.0  13800.0  1937.0  1832.0   \n",
       "17     -1.0  21036.0    0.251902   0.748098  3732.0  13590.0  2147.0  1567.0   \n",
       "18     -1.0  21036.0    0.251902   0.748098  3573.0  14002.0  1735.0  1726.0   \n",
       "19     -1.0  21036.0    0.251902   0.748098  3887.0  13271.0  2466.0  1412.0   \n",
       "20     -1.0  21036.0    0.251902   0.748098  3591.0  13932.0  1805.0  1708.0   \n",
       "21     -1.0  21036.0    0.251902   0.748098  3451.0  14178.0  1559.0  1848.0   \n",
       "22     -1.0  21036.0    0.251902   0.748098  3780.0  13271.0  2466.0  1519.0   \n",
       "\n",
       "         FPR  specificity  sensitivity  precision  accuracy  \\\n",
       "0   0.117939     0.882061     0.652010   0.650537  0.824111   \n",
       "1   0.153269     0.846731     0.706737   0.608251  0.811466   \n",
       "2   0.139989     0.860011     0.685790   0.622580  0.816125   \n",
       "3   0.107962     0.892038     0.638422   0.665683  0.828152   \n",
       "4   0.170871     0.829129     0.728062   0.589278  0.803670   \n",
       "5   0.140751     0.859249     0.688432   0.622207  0.816220   \n",
       "6   0.140116     0.859884     0.691451   0.624297  0.817456   \n",
       "7   0.122768     0.877232     0.665409   0.646024  0.823873   \n",
       "8   0.120099     0.879901     0.668805   0.652190  0.826726   \n",
       "9   0.113999     0.886001     0.655784   0.659518  0.828009   \n",
       "10  0.134714     0.865286     0.683903   0.630919  0.819595   \n",
       "11  0.137256     0.862744     0.681449   0.625715  0.817075   \n",
       "12  0.118892     0.881108     0.670881   0.655179  0.828152   \n",
       "13  0.137256     0.862744     0.694471   0.630137  0.820356   \n",
       "14  0.130711     0.869289     0.686356   0.638743  0.823208   \n",
       "15  0.140878     0.859122     0.690885   0.622831  0.816743   \n",
       "16  0.123086     0.876914     0.654274   0.641562  0.820831   \n",
       "17  0.136430     0.863570     0.704284   0.634802  0.823446   \n",
       "18  0.110250     0.889750     0.674278   0.673135  0.835473   \n",
       "19  0.156701     0.843299     0.733535   0.611837  0.815649   \n",
       "20  0.114698     0.885302     0.677675   0.665493  0.833001   \n",
       "21  0.099066     0.900934     0.651255   0.688822  0.838040   \n",
       "22  0.156701     0.843299     0.713342   0.605187  0.810563   \n",
       "\n",
       "    balanced accuracy        f1       auc  \n",
       "0            0.767036  0.651272  0.865983  \n",
       "1            0.776734  0.653806  0.868766  \n",
       "2            0.772901  0.652658  0.866253  \n",
       "3            0.765230  0.651768  0.865983  \n",
       "4            0.778595  0.651359  0.866293  \n",
       "5            0.773840  0.653646  0.867091  \n",
       "6            0.775668  0.656160  0.868717  \n",
       "7            0.771320  0.655573  0.867634  \n",
       "8            0.774353  0.660393  0.870440  \n",
       "9            0.770893  0.657646  0.869842  \n",
       "10           0.774594  0.656343  0.867364  \n",
       "11           0.772097  0.652394  0.864976  \n",
       "12           0.775995  0.662937  0.873003  \n",
       "13           0.778607  0.660742  0.872713  \n",
       "14           0.777822  0.661694  0.870665  \n",
       "15           0.775003  0.655095  0.864621  \n",
       "16           0.765594  0.647856  0.861911  \n",
       "17           0.783927  0.667740  0.876492  \n",
       "18           0.782014  0.673706  0.883135  \n",
       "19           0.788417  0.667182  0.879088  \n",
       "20           0.781489  0.671529  0.879739  \n",
       "21           0.776095  0.669512  0.879535  \n",
       "22           0.778321  0.654829  0.864204  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdi_tr.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN THE MODEL WITH 9 CLUSTERS\n",
    "d_newborn_tr, d_newborn_te = train_test_split(sparcs, test_size=0.2, random_state = 1512)\n",
    "Xtrain, Xtest = d_newborn_tr.iloc[:,0:-1].values, d_newborn_te.iloc[:,0:-1].values\n",
    "ytrain, ytest = d_newborn_tr.iloc[:,-1].values.astype(int), d_newborn_te.iloc[:,-1].values.astype(int)\n",
    "\n",
    "C = [0.01, 0.1, 1, 5, 10, 15, 20, 50]\n",
    "max_iter2 = 30\n",
    "n_clusters = 9\n",
    "\n",
    "model = SupervisedGMM(C = C, max_iter2 = max_iter2, n_clusters = n_clusters, verbose = 0)\n",
    "model = model.fit(Xtrain = Xtrain, ytrain = ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAKE THE STATISTICS OF THE MODEL\n",
    "#take probabilities of test and train\n",
    "probTrain = model.predict_proba( Xtrain )\n",
    "probTest = model.predict_proba( Xtest )\n",
    "\n",
    "#take the results\n",
    "results_last = sgmmResults( model, probTest.copy(), probTrain.copy(), ytest, ytrain, tau = None,\n",
    "                mode = 0)\n",
    "\n",
    "train_metrics = results_last[\"trainMet\"]\n",
    "test_metrics = results_last[\"testMet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVERALL METRICS ON TEST DATA WITH 9 CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PER CLUSTER STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get memberships and labels\n",
    "memb_train = model.predict_GMMS(Xtrain)\n",
    "memb_test = model.predict_GMMS(Xtest)\n",
    "\n",
    "#get hard labels\n",
    "testlabels = np.argmax(memb_test, axis = 1)\n",
    "trainlabels = np.argmax(memb_train, axis = 1)\n",
    "\n",
    "#get logistic regression per cluster models\n",
    "per_cluster_regressions = model.LogRegr\n",
    "\n",
    "#het the per cluster metrics\n",
    "clust_Train, clust_Test = metrics_cluster(models = per_cluster_regressions, ytrain = ytrain, ytest = ytest,\n",
    "                                         testlabels = testlabels, trainlabels = trainlabels, Xtrain = Xtrain,\n",
    "                                          Xtest = Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PRINT CLUSTER TEST\n",
    "print(\"PER CLUSTER METRICS FOR TEST DATA\\n\")\n",
    "print(clust_Test)\n",
    "print(\"\\n\\n\\nPER CLUSTER METRICS FOR TRAINING DATA\\n\")\n",
    "print(clust_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just change the order of labels so that cost for each cluster goes from low to high\n",
    "\n",
    "Labels = np.append(trainlabels, testlabels)\n",
    "\n",
    "target= pd.DataFrame(np.append(ytrain, ytest,axis=0),columns=['Target'])\n",
    "cadre = pd.DataFrame(Labels,columns=['Cadre'])\n",
    "\n",
    "target['Cadre']= cadre['Cadre']\n",
    "\n",
    "highcostratio = np.array([])\n",
    "clustpop = np.array([])\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    pop = target[target['Cadre']==i]['Target'].shape[0]\n",
    "    clustpop = np.append(clustpop,pop)\n",
    "    ratio = np.count_nonzero(target[target['Cadre']==i]['Target'].values)*1.0/pop\n",
    "    highcostratio= np.append(highcostratio,ratio)\n",
    "    \n",
    "x = np.arange(n_clusters)\n",
    "b=sns.lineplot(x=x,\n",
    "               y=sorted(highcostratio))\n",
    "plt.xticks(x,x)\n",
    "#b.set_xlabel(\"X Label\",fontsize=30)\n",
    "b.set_ylabel(\"high-cost ratio\",fontsize=12)\n",
    "b.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order labels\n",
    "sortedLabels = np.argsort( highcostratio ).tolist()\n",
    "Labels2 = np.zeros( Labels.shape)-1\n",
    "index = 0\n",
    "\n",
    "for sortedNumber in sortedLabels:\n",
    "    inNumber = np.where( Labels == sortedNumber)[0]\n",
    "    Labels2[inNumber] = index\n",
    "    index += 1\n",
    "Labels = Labels2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot highcost ratio among cadres\n",
    "# from highcostratio import highcostplot\n",
    "# target,Labels,highcostratio,remove_index = highcostplot(d_newborn_tr,d_newborn_te, newborn_best)\n",
    "# # the log odds ratios of being highcost in different clusters\n",
    "from ftest_logodds import restest\n",
    "\n",
    "restest(np.expand_dims(Labels,axis=1),\n",
    "        np.expand_dims(target['Target'],axis=1)).round(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log odds ratios for feature vs. cluster, uncorr\n",
    "from ftest_logodds import ftest_uncorr\n",
    "\n",
    "features = list(d_newborn_tr.iloc[:,:-1])\n",
    "data = np.append(d_newborn_tr.iloc[:,:-1],d_newborn_te.iloc[:,:-1],axis=0)\n",
    "np_feat = np.asarray(features)\n",
    "labs = np.expand_dims(Labels,axis=1)\n",
    "feat_table,lor_table =ftest_uncorr(data,labs,np_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce feature length\n",
    "new_feat = [s.replace('CCS.DX_' , '') for s in features]\n",
    "new_feat = [s.replace('CCS.PROC_' , '') for s in new_feat]\n",
    "new_feat = [s.replace(' not mental disorders or infectious disease','')for s in new_feat]\n",
    "new_feat = [s.replace('birth weight; and','BW&')for s in new_feat]\n",
    "new_feat = [s.replace('sexually transmitted disease','STD')for s in new_feat]\n",
    "new_feat = [s.replace('tuberculosis','TB')for s in new_feat]\n",
    "new_feat = [s.replace('system','syst')for s in new_feat]\n",
    "new_feat = [s.replace('Other','Ot')for s in new_feat]\n",
    "new_feat = [s.replace('OTHER','Ot')for s in new_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustermaps of segments of features.\n",
    "# Red indicates a given feature has significant positive log ordds ratio to a given cluster, \n",
    "# light purple no significance, blue significant negative.\n",
    "from clustmap import plotclustmap\n",
    "\n",
    "sns.set(font_scale=1.1)\n",
    "# racial features\n",
    "plotclustmap(feat_table[:,11:19].T,None,np.array(new_feat)[11:19],None,None)\n",
    "plt.yticks(rotation=0) \n",
    "# county features\n",
    "plotclustmap(feat_table[:,3:8].T,None,np.array(new_feat)[3:8],None,None)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# # # admission features\n",
    "plotclustmap(feat_table[:,19:23].T,None,np.array(new_feat)[19:23],None,None)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# ER, Low BW, Inflow\n",
    "plotclustmap(feat_table[:,0:3].T,None,np.array(new_feat)[0:3],None,None)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# # #disease features\n",
    "plotclustmap(feat_table[:,23:72].T,None,np.array(new_feat)[23:72],None,None)\n",
    "# # # procedure features\n",
    "plotclustmap(feat_table[:,72:116].T,None,np.array(new_feat)[72:116],None,None)\n",
    "plotclustmap(feat_table[:,116:].T,None,np.array(new_feat)[116:],None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weights = np.array(model.weights)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the weights\n",
    "N = weights.shape[0]\n",
    "from clustmap import plotclustmap\n",
    "plotclustmap(weights.T[abs(weights.T).sum(axis = 1)/N > 1],None, np.array(new_feat)[abs(weights.T).sum(axis = 1)/N > 1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a binary version of the weights: red, weight>0, blue , weight <0\n",
    "bin_weights = (newborn_best.W[abs(newborn_best.W.T).sum()>1e-1]>0)*1 + (newborn_best.W[abs(newborn_best.W.T).sum()>1e-1]<0)*(-1) \n",
    "plotclustmap(bin_weights,None,np.array(new_feat)[abs(newborn_best.W.T).sum()>1e-1],None,None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
