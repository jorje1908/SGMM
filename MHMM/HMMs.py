#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Jul  9 14:08:17 2019

@author: george

Implements 
--> A hidden Markov Model and extends to
--> a Mixture of Hidden Markov Models,

--> Observational Model is consisted by a Mixture of 
Gaussians Model,

--> The Model will be trained by the Expectation Maximization
    Algorithm 


"""

import numpy as np
from scipy.stats import multivariate_normal

class HMM(object):
    """ Helper HMM class """
    
    
    
    def __init__(self, states = 2, g_components = 2, t_cov = "diag"):
        
        #Setting states attribute
        self.states_ = states
        #Setting Gaussian components attribute
        self.g_components_ = g_components
        #initialize Transition Matrix
        self.A = np.zeros( shape = [states, states], dtype = 'float')
        #initilize initial distribution probabilities np.array pi[k] k = 1...K
        self.pi = np.zeros( shape = states, dtype = 'float')
        
        #4d array cov[k,l,d,d] kth state lth gaussian component
        self.cov = None
    
        #3d array means[k,l,d] kth state lth mean
        self.means = None
    
        #list of gaussian predictors gauss[k,l] lth gaussian of kth state
        #each gauss[k][l] component is an instance of the multivariate_normal
        #scipy object
        self.gauss = None
        #initial probabilities of each gaussian component, for each state
        #alpha[k,l] kth state lth component
        self.alpha = None
        
    def predict_states_All(self, X ):
        """
        computes the probability to observe a x_t for all t = 1...T
        for all states K = 1...K
        for any observation in time it calculates the probability 
        using the method predict_states
        
        X is a sequence of observations x1, ... xT
        numpy array Txd
        
        return the matrix P[k,t] probability to observe x_t given state k
        
        """
        
        #get the number of sequneces in time
        T = X.shape[0]
        #get number of states
        K = self.states_
        
        P_all = np.array( shape = [K, T])
        
        for t in np.arange( T ):
            P_all[:, t] = self.predict_states( X[t] )
        
        return P_all
        
    def predict_states(self, x):
        """ 
         calculates the probability of x to be observed given a state,
         for all states and returns a matrix 
         P(x) = [p(x_t|z_t = 1)... p(x_t|z_t = k)]
        
        """
        K = self.states_
        P = np.zeros( shape = [K] )
        
        for k in np.arange( K ):
            P[k] = self.predict_state( x, st = k)
            
        return P
        
        
    def predict_state(self, x, st = None):
         """
         calculates the probabiity of an observation to be generated 
         by the state "state" --> p(x_t | z_t = k)
         
         returns a matrix kx1
         
         """
         
         components = self.g_components_
         pk = 0
         
         for component in np.arange( components ):
             pk += self.predict_state_comp( x, st = st, cmp = component)
             
         return pk
            
         
         
    def predict_state_comp(self, x, st = None, cmp = None):
         
         """ 
         predicts the probability of an observation to be generated
         by the lth component gaussian of the kth state
         
         st: HMM  state {1...K}
         cmp: Kth state lth Gaussian Component l = {1...L}
         
         p( G_t = l, x_t |  z_t = k)
         
         """
         
         #get the multivariate_gaussian of state = "state"
         #component = "comp"
         gaussian_kl = self.gauss[st][ cmp ]
         #get the probability of this component to be chosen
         alpha_kl = self.alpha[st, cmp]
         #predict the probability of x to be generated by the lth component
         #of
         pkl = gaussian_kl.pdf( x )*alpha_kl
         
         return pkl
     
    def forward(self, X):
        """
        Implements the forward Algorithm, 
        Returns tha matrix forw [ a_1,... a_T ]
        where a_t = [at[1], ... ai[K]]^(transpose)
        where ai[k] = p( z_i = k, x_1...x_t)
        
        X is a sequence of observations x1, ... xT
        numpy array Txd
        
        """
       
        #get length of obseravtions in time
        T = X.shape[0]   
        #get number of states
        K = self.states_
        #get transition matrix Aij = p(z(t) = j|z(t-1) = i)
        A = self.A
        #initialize forward matrix
        forw = np.zeros( shape = [K, T])
        
        #take initial alphas a_1
        forw[:,0] = self.predict_states(X[0])*self.pi
        
        for t in np.arange(1, T):
            
            forw[:,t] = self.predict_states( X[t] )*(A.T@ forw[:, t-1] )
            
        return forw
    
    
    def backward(self, X):
        """
        Implements the Backward algorithm
        Returns the matrix backw [b_1,..., b_T]
        where b_t = [bt[1],..., bt[K]]
        where bt[k] = p(x_(t+1)...x_T| z_t = k)
        
        X is a sequence of observations x1, ... xT
        numpy array Txd
        
        """
        
        #get length of obseravtions in time
        T = X.shape[0]   
        #get number of states
        K = self.states_
        #get transition matrix Aij = p(z(t) = j|z(t-1) = i)
        A = self.A
        #initialize backward matrix
        backw = np.zeros( shape = [K, T])
        
        #initialize backw matrix at time T
        backw[:, T-1] = 1
        
        for t in np.arange( T-2, -1, -1):
            
            backw[:, t] = A.T@( self.predict_states( X[t+1]*backw[:,t+1]))
            
        return backw
    
    
    def gamas( self, X):
        
        """
        Computes th eprobability of being at state k at time t given
        we have observed all the sequence x1...xT,
        it is called  smoothed probability on hmms 
        p(z_t = k| O1...OT)
        
        X is a sequence of observations x1, ... xT
        numpy array Txd
        
        returns the gamma matrix  a KxT numpy array K are the HMM states
        T is the length of sequence in time
        
        """
        
        #regularization
        reg = 10**( -6 )
        
        #run forward algorithm_
        forw = self.forward( X )
        #run backward algorithm
        backw = self.backward( X )
        #calculate gamma unnormalized
        gamma = forw*backw 
        gammaSumCol = np.sum( gamma, axis = 0)
        #calculate final gamma
        gamma = gamma/( gammaSumCol + reg )
        
        return gamma


    def sliced( self, X):

        """
        Computes the sliced probability  p(z_t = i, Z_(t+1) = j| o1...T)
        
        returns a KxKxT-1 matrix  xis with the aformentioned probabilities
        
        """
        
        #get length of obseravtions in time
        T = X.shape[0]   
        #get number of states
        K = self.states_
        #get transition matrix Aij = p(z(t) = j|z(t-1) = i)
        A = self.A
        #initialize xis matrix
        xis = np.array( shape = [K, K, T-1 ])
        
        #compute observation proabilities for all time steps of X
        Pkt = self.predict_states_All( X )
        #compute forward
        forw = self.forward( X )
        #compute backward 
        backw = self.backward( X )
        
        for t in np.arange( T-1 ):
            
            xis[:, :, t] = (A.T*forw[:, t]).T*( Pkt[:, t+1]*backw[:, t+1] )
            xisSum = np.sum( xis[:, :, t])
            xis[:,:,t] = xis[:,:,t]/xisSum
            
        return xis
    
    def g(self, x_i):
        """
        calculates the posterior probabilities 
        
        p(G = l|x_t, H = m, z_t = k)
        for all l = {1,...,L}
                t = {1,...,T}
                z_t = {1,...K}
                
        return an KXLXT matrix containing the gkl(t) of the derivation
        x_i is a Txd array having the observations in time
        """
        #get the time up to observations reach T
        T = x_i.shape[0]
        #get the number of states
        states = self.states_
        #get the number of gaussian components
        L = self.g_components_
        #initialize matrix
        gs = np.zeros( shape = [states, L, T] )
        
        for state in np.arange( states ):
            gs[state, :, :] = self.g_state( x_i, state )
            
        return gs
            
    
    def g_state(self, x_i, st = None):
        """
        computes the probability p(G_t = l|z_t = k, x_t)
        for state z_t = st and component G_t = comp
        for each time observation o_t t=1 ...T 
        for each component
        thus returning a :
        
        LxT matrix
        
        x_i = [x_i(1),...x_i(T)]
        """
        #number of gaussian components
        gauss_comp = self.g_components_
        #number of observations in time
        T = x_i.shape[0]
        #initialize the matrix to return
        pk = np.zeros( shape = [gauss_comp, T])
        
        for cmp in np.arange( gauss_comp ):
            pk[cmp, :] = self.predict_state_comp(x_i, st = st, cmp = cmp)
        
        #get the component wise sum for each sample in time
        sumPk = np.sum( pk, axis = 0)
        #normalize the pk matrix such that every column sums to 0
        pk = pk/sumPk
        return pk
        
    
    def EM_init(self, X):
        """
        Initialize the HMM parameters
        """
        pass
    
    def EM_iter(self, X, r_m):
        """ 
        
        EM iteration updating all the 
        HMM parameteres
        
        A: state transition matrix
        pi: initial state probabilities
        alpha: gaussian mixing coefficients [k,l] matrix
        means: Gaussian Means [k,l,d] matrix
        cov: Coavriance matrices for the Gaussians [k,l,d,d]
        
        sets the A,pi, alpha, means, cov
        and gauss: gaussian components objects (frozen)
        
        X: is a list of obseravtions O^(1)... O^(N)
        O^(i) = [o_1^(i),....o_T^(i)]
        
        r_m: N dimensional matrix with the posterior probability p(H = m|X)
        which the probability of this HMM to be chosen given the observations
        X
        
        """
        
        K = self.states_
        #initializing attributes needed
        
        self.pi_Sum = np.zeros( shape = [K] )
        self.rm_Sum = np.sum(r_m)
        self.A_nom = np.zeros( shape = [K,K] )
        self.A_den = np.zeros( shape = [K] )
        self.g
        
        for i in np.arange( len(X) ):
            #get the ith observation
            x_i = X[i]
            #get the gammas for the i_th observation
            gamma_i = self.gamas( x_i )
            #get xis for the i_th observation
            xis_i = self.sliced( x_i )
            #get the rm_i
            rm_i = r_m[i]
            #get g_is for the ith observation
            g_i = self.gs( x_i )
            
            #update sum of pis
            self.update_pi( gamma_i[:, 0], rm_i )
            #update A matrix nominator and denominator
            self.update_A( xis_i, gamma_i, rm_i )
            
            
        
    def update_pi(self,  gi1, rm_i):
        """ 
        updates the initial state parameter probabilities
        for all the states
        p(z_1 = k|H = m)
        
        self.pi_Sum ---> the value to update
        
        USED IN EM_iter method
        """
        
        self.checkShape( self.pi_Sum, gi1, 'update_pi')
        self.pi_Sum += gi1*rm_i / (self.rm_Sum)
        
        return
        
        
    def update_A(self, xis_i, gamma_i,  rm_i):
        """
        updates the sum of 
        self.A_nom
        self.A_den
        
        """
        self.A_nom += np.sum( xis_i, axis = 2)*rm_i
        self.A_den += np.sum( gamma_i, axis = 1)*rm_i
        
        return 
        
        
        
    def update_alpha(self, X_i):
        pass
    
    def update_pi_part(self):
        pass
    
    
    
    
    def update_alpha_part(self):
        pass
    
    
    
    
    
    def update_A_part(self, X_i):
        pass
    
    
    def update_means(self, X_i):
        pass
    
    def update_means_part(self, X_i):
        pass
    
    def update_cov(self, X_i):
        pass
    
    def update_cov_part(self, X_i):
        pass
    
    
    
    
    
    #########     check functions   #########
    def checkShape( self, arg1, arg2, name):
        
        if arg1.shape != arg2.shape:
            print( "Warning shapes does not match in " + name)
        
        
        return
        
    
    
    
    
        
        
            
        
        
        
        
        
        
        
        
        
        
        
        
        
        
         
         
         
         
         


class MHMM(object):
    pass